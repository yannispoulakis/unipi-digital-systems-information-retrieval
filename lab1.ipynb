{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77ca5be2",
   "metadata": {},
   "source": [
    "# Εργαστήριο 1ο - Ανάκτηση Πληροφοριών\n",
    "## Τμήμα Ψηφιακών Συστημάτων - Πανεπιστήμιο Πειραιά\n",
    "\n",
    "Διδάσκων Καθηγητής: Δουλκερίδης Χρήστος <br />\n",
    "Υπ. Διδάκτωρας: Πουλάκης Γιάννης"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f85a20",
   "metadata": {},
   "source": [
    "## Εργαστήριο 1ο \n",
    "\n",
    "Στόχος του πρώτου εργαστηρίου είναι η προσπέλαση αρχείων που εμπεριέχουν κείμενο, καθώς και η επεξεργασία του εξαγώμενου κειμένου που θα αξιοποιηθεί περαιτέρω σε επόμενα μαθήματα.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8249faff",
   "metadata": {},
   "source": [
    "## Ασκηση 1 - Προσπέλαση Εγγράφου\n",
    "\n",
    "Η πρώτη άσκηση είναι η δημιουργία μεθόδου, η οποία θα μας επιτρέπει την προσπέλαση αρχείων μορφής .txt που βρίσκονται σε συγκεκριμένη διαδρομή στον υπολογιστή. Τα δεδομένα προς αξιοποίηση βρίσκονται στην ενότητα \"Έγγραφα\\Εργαστήριο\" στην σελίδα του μαθήματος στην πλατφόρμα \"Αρίσταρχος\". \n",
    "\n",
    "https://aristarchus.ds.unipi.gr/\n",
    "\n",
    "Συγκεκριμένα, η μέθοδος θα πρέπει να λαμβάνει την διαδρομή του αρχείου και να εξάγει μια λίστα, όπου αντικείμενα της θα είναι οι εκάστοτε προτάσεις. Στην λίστα εξόδου δεν θα πρέπει να περιλαμβάνονται κενές γραμμές.\n",
    "\n",
    "Για αυτή την άσκηση υπάρχουν δύο προσεγγίσεις : <br/>\n",
    "a) H χρήση for loop <br/>\n",
    "b) H χρήση της readlines()\n",
    "\n",
    "Να εμφανίσετε τις 5 πρώτες γραμμές ως παράδειγμα. \n",
    "\n",
    "**Προσοχή!**\n",
    "Είναι σημαντικό στις μεθόδους που χρησιμοποιούνται, να υπάρχουν σχόλια, όπου αυτό κρίνεται απαραίτητο και να δηλώνονται οι τύποι των μεταβλητών εισόδου και εξόδου, προκειμένου να υπάρχει σαφήνεια. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e22ed9",
   "metadata": {},
   "source": [
    "### Μέθοδος 1 - For Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eca1d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_txt(filepath:str) -> list:\n",
    "    lines_list = []\n",
    "    with open(filepath,\"r+\") as f: # note that encoding nees to be specified in some cases\n",
    "        for line in f: \n",
    "            if line.strip(): # checks if line is not empty\n",
    "                lines_list.append(line)\n",
    "                \n",
    "    return lines_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993fb1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"New Zealand's current account deficit for the quarter ended December 31 ,1986 narrowed to 567 mln dlrs from 738 mln ,revised down from 742 mln ,for the September quarter and from 733 mln a year earlier ,the statistics department said .The deficit for the year ended December narrowed to 2.75 billion dlrs from 2.91 billion dlrs ,revised down from 2.92 billion ,for the year ended September .The deficit for calendar 1985 was 2.61 billion .The December quarter showed a 182 mln dlr surplus for merchandise trade ,unchanged from the September quarter surplus which was revised down from 271 mln dlrs .The 1985 December quarter showed a 13 mln dlr deficit .Imports for the December 1986 quarter were 2.655 billion against 2.883 billion in the September quarter and 2.454 a year earlier .Exports were 2.837 billion against 3.065 billion and 2.440 billion .Imports for the year ended December 1986 were 10.74 billion dlrs compared with 11.14 billion in 1985 .Exports were 11.20 billion against 11.36 billion .Government borrowing stood at 9.26 billion dlrs for calendar 1986 against 3.15 billion for 1985 .Borrowing in the December quarter rose to 3.92 billion from 1.79 in the September quarter and 611 mln a year earlier .Repayments stood at 5.5 billion for the year ,up from 3.1 billion in 1985 .Repayments in the December quarter accounted for 1.4 billion dlrs against 260 mln in the September quarter and 334 mln a year earlier .Official reserves totalled 7.205 billion dlrs at end December compared with 4.723 billion at end September and 3.255 billion one year earlier .REUTER 3 \"]\n"
     ]
    }
   ],
   "source": [
    "lines = parse_txt(r\"C:\\Users\\giann\\OneDrive\\Υπολογιστής\\Unipi_Master\\Information Retrieval Course Bachelor\\reuters\\data\\bop\\reut2-000x879.txt\")\n",
    "print(lines[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df6f341",
   "metadata": {},
   "source": [
    "### Μεθοδος 2 - readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a69a99f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ascii\n"
     ]
    }
   ],
   "source": [
    "# Πως ελέγχουμε το encoding ενός εγγράφου΄΄; - Chardet  \n",
    "import chardet    \n",
    "rawdata = open(r\"C:\\Users\\giann\\OneDrive\\Υπολογιστής\\Unipi_Master\\Information Retrieval Course Bachelor\\reuters\\data\\bop\\reut2-000x879.txt\", 'rb').read()\n",
    "result = chardet.detect(rawdata)\n",
    "charenc = result['encoding']\n",
    "print(charenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8b99fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_txt(filepath:str, encoding) -> list:\n",
    "    with open(filepath, \"r+\",encoding = encoding) as f: \n",
    "        lines = f.readlines()\n",
    "        lines = [l for l in lines if l.strip()] # In readlines() we filter empty rows with a generator \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23718343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"New Zealand's current account deficit for the quarter ended December 31 ,1986 narrowed to 567 mln dlrs from 738 mln ,revised down from 742 mln ,for the September quarter and from 733 mln a year earlier ,the statistics department said .The deficit for the year ended December narrowed to 2.75 billion dlrs from 2.91 billion dlrs ,revised down from 2.92 billion ,for the year ended September .The deficit for calendar 1985 was 2.61 billion .The December quarter showed a 182 mln dlr surplus for merchandise trade ,unchanged from the September quarter surplus which was revised down from 271 mln dlrs .The 1985 December quarter showed a 13 mln dlr deficit .Imports for the December 1986 quarter were 2.655 billion against 2.883 billion in the September quarter and 2.454 a year earlier .Exports were 2.837 billion against 3.065 billion and 2.440 billion .Imports for the year ended December 1986 were 10.74 billion dlrs compared with 11.14 billion in 1985 .Exports were 11.20 billion against 11.36 billion .Government borrowing stood at 9.26 billion dlrs for calendar 1986 against 3.15 billion for 1985 .Borrowing in the December quarter rose to 3.92 billion from 1.79 in the September quarter and 611 mln a year earlier .Repayments stood at 5.5 billion for the year ,up from 3.1 billion in 1985 .Repayments in the December quarter accounted for 1.4 billion dlrs against 260 mln in the September quarter and 334 mln a year earlier .Official reserves totalled 7.205 billion dlrs at end December compared with 4.723 billion at end September and 3.255 billion one year earlier .REUTER 3 \"]\n"
     ]
    }
   ],
   "source": [
    "lines = parse_txt(r\"C:\\Users\\giann\\OneDrive\\Υπολογιστής\\Unipi_Master\\Information Retrieval Course Bachelor\\reuters\\data\\bop\\reut2-000x879.txt\", encoding = charenc)\n",
    "print(lines[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b47d218",
   "metadata": {},
   "source": [
    "## Άσκηση 2 \n",
    "\n",
    "\n",
    "Για την δεύτερη άσκηση του εργαστηρίου οι φοιτητές καλούνται να δημιουργήσουν μια μέθοδο η οποία για κάθε γράμμή του κειμένου εφαρμόζει μερικές απο τις βασικότερες μεθόδους προεπεξεργασίας κειμένου. Συνιστάται η χρήση της βιβλιοθήκης nltk η οποία έχει δημιουργηθεί με στόχο την επεξεργασία κειμένου. Συγκεκριμένα οι τεχνικές προεπεξεργασίας οι οποίες ζητούνται είναι οι εξής:  <br/><br/>\n",
    "\n",
    "a) Punctuation Removal <br/>\n",
    "b) Text Lowering <br/>\n",
    "c) Tokenization <br/>\n",
    "d) Lemmatization <br/>\n",
    "e) Stop-Words Removal  <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0b76db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Zealands current account deficit for the quarter ended December 31 1986 narrowed to 567 mln dlrs from 738 mln revised down from 742 mln for the September quarter and from 733 mln a year earlier the statistics department said The deficit for the year ended December narrowed to 275 billion dlrs from 291 billion dlrs revised down from 292 billion for the year ended September The deficit for calendar 1985 was 261 billion The December quarter showed a 182 mln dlr surplus for merchandise trade unchanged from the September quarter surplus which was revised down from 271 mln dlrs The 1985 December quarter showed a 13 mln dlr deficit Imports for the December 1986 quarter were 2655 billion against 2883 billion in the September quarter and 2454 a year earlier Exports were 2837 billion against 3065 billion and 2440 billion Imports for the year ended December 1986 were 1074 billion dlrs compared with 1114 billion in 1985 Exports were 1120 billion against 1136 billion Government borrowing stood at 926 billion dlrs for calendar 1986 against 315 billion for 1985 Borrowing in the December quarter rose to 392 billion from 179 in the September quarter and 611 mln a year earlier Repayments stood at 55 billion for the year up from 31 billion in 1985 Repayments in the December quarter accounted for 14 billion dlrs against 260 mln in the September quarter and 334 mln a year earlier Official reserves totalled 7205 billion dlrs at end December compared with 4723 billion at end September and 3255 billion one year earlier REUTER 3 \n"
     ]
    }
   ],
   "source": [
    "# Punctuation Removal\n",
    "import string\n",
    "exclude = set(string.punctuation)\n",
    "s = ''.join(ch for ch in lines[0] if ch not in exclude)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce487e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new zealands current account deficit for the quarter ended december 31 1986 narrowed to 567 mln dlrs from 738 mln revised down from 742 mln for the september quarter and from 733 mln a year earlier the statistics department said the deficit for the year ended december narrowed to 275 billion dlrs from 291 billion dlrs revised down from 292 billion for the year ended september the deficit for calendar 1985 was 261 billion the december quarter showed a 182 mln dlr surplus for merchandise trade unchanged from the september quarter surplus which was revised down from 271 mln dlrs the 1985 december quarter showed a 13 mln dlr deficit imports for the december 1986 quarter were 2655 billion against 2883 billion in the september quarter and 2454 a year earlier exports were 2837 billion against 3065 billion and 2440 billion imports for the year ended december 1986 were 1074 billion dlrs compared with 1114 billion in 1985 exports were 1120 billion against 1136 billion government borrowing stood at 926 billion dlrs for calendar 1986 against 315 billion for 1985 borrowing in the december quarter rose to 392 billion from 179 in the september quarter and 611 mln a year earlier repayments stood at 55 billion for the year up from 31 billion in 1985 repayments in the december quarter accounted for 14 billion dlrs against 260 mln in the september quarter and 334 mln a year earlier official reserves totalled 7205 billion dlrs at end december compared with 4723 billion at end september and 3255 billion one year earlier reuter 3 \n"
     ]
    }
   ],
   "source": [
    "# Text Lowering\n",
    "print(s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cf76f94",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30780/925116549.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"punkt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtokenized_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenized_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "# H Κλάση string έχει built-in την μέθοδο .strip() η οποία χωρίζει κείμενο σε αντικείμενα λίστας με βάση μια σειρά χαρακτήρων. \n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "tokenized_s = word_tokenize(s)\n",
    "print(tokenized_s[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe96c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "# Προσοχή! Πρέπει να δημιουργηθεί για κάθε λέξη ένα tag το οποίο να υποδυκνύει την φύση της λέξης\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenized_s_new = []\n",
    "for word,tag in pos_tag(tokenized_s):\n",
    "    wntag = tag[0].lower()\n",
    "    wntag = wntag if wntag in ['a', 'r', 'n', 'v'] else None\n",
    "    lemma = lemmatizer.lemmatize(word, wntag) if wntag else word\n",
    "    print (lemma, word)\n",
    "    tokenized_s_new.append(lemma)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16b55c07",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30780/3370149067.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Stop Word Removal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"stopwords\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"english\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtokenized_s_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenized_s_new\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "# Stop Word Removal \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "tokenized_s_new = [word for word in tokenized_s_new if not word.lower() in stop_words]\n",
    "print(tokenized_s_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e6f8be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\giann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\giann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\giann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\giann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\giann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# complete method \n",
    "# Imports and nltk specific downloads\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "def preprocess_txt(input_txt) -> list: \n",
    "    text_in_lines = []\n",
    "    for line in input_txt: \n",
    "        # Punctuation Removal\n",
    "        exclude = set(string.punctuation)\n",
    "        s = ''.join(ch for ch in lines[0] if ch not in exclude)\n",
    "        \n",
    "        # Text Lowering\n",
    "        s = s.lower()\n",
    "        \n",
    "        # Tokenization\n",
    "        tokenized_s = word_tokenize(s)\n",
    "        \n",
    "        # Lemmatization\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokenized_s_new = []\n",
    "        for word,tag in pos_tag(tokenized_s):\n",
    "            wntag = tag[0].lower()\n",
    "            wntag = wntag if wntag in ['a', 'r', 'n', 'v'] else None\n",
    "            lemma = lemmatizer.lemmatize(word, wntag) if wntag else word\n",
    "            tokenized_s_new.append(lemma)\n",
    "        \n",
    "        # Stop Word Removal \n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        tokenized_s_new = [word for word in tokenized_s_new if not word.lower() in stop_words]\n",
    "        text_in_lines = text_in_lines + tokenized_s_new\n",
    "        return text_in_lines\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d69c6eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new', 'zealand', 'current', 'account', 'deficit', 'quarter', 'end', 'december', '31', '1986', 'narrow', '567', 'mln', 'dlrs', '738', 'mln', 'revise', '742', 'mln', 'september', 'quarter', '733', 'mln', 'year', 'earlier', 'statistic', 'department', 'say', 'deficit', 'year', 'end', 'december', 'narrow', '275', 'billion', 'dlrs', '291', 'billion', 'dlrs', 'revise', '292', 'billion', 'year', 'end', 'september', 'deficit', 'calendar', '1985', '261', 'billion', 'december', 'quarter', 'show', '182', 'mln', 'dlr', 'surplus', 'merchandise', 'trade', 'unchanged', 'september', 'quarter', 'surplus', 'revise', '271', 'mln', 'dlrs', '1985', 'december', 'quarter', 'show', '13', 'mln', 'dlr', 'deficit', 'import', 'december', '1986', 'quarter', '2655', 'billion', '2883', 'billion', 'september', 'quarter', '2454', 'year', 'earlier', 'export', '2837', 'billion', '3065', 'billion', '2440', 'billion', 'import', 'year', 'end', 'december', '1986', '1074', 'billion', 'dlrs', 'compare', '1114', 'billion', '1985', 'export', '1120', 'billion', '1136', 'billion', 'government', 'borrow', 'stand', '926', 'billion', 'dlrs', 'calendar', '1986', '315', 'billion', '1985', 'borrowing', 'december', 'quarter', 'rise', '392', 'billion', '179', 'september', 'quarter', '611', 'mln', 'year', 'earlier', 'repayment', 'stand', '55', 'billion', 'year', '31', 'billion', '1985', 'repayment', 'december', 'quarter', 'account', '14', 'billion', 'dlrs', '260', 'mln', 'september', 'quarter', '334', 'mln', 'year', 'earlier', 'official', 'reserve', 'total', '7205', 'billion', 'dlrs', 'end', 'december', 'compare', '4723', 'billion', 'end', 'september', '3255', 'billion', 'one', 'year', 'earlier', 'reuter', '3']\n"
     ]
    }
   ],
   "source": [
    "pre_txt = preprocess_txt(lines)\n",
    "print(pre_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f7520",
   "metadata": {},
   "source": [
    "## Άσκηση 3η - Αναδρομική εξερεύνηση φακέλων για αρχεία\n",
    "Τέλος οι φοιτητές καλούνται να δημιουργήσουν μια μέθοδο η οποία να μπορεί να διατρέξει όλους τους υποφακέλους ενός φακέλου, να διαβάσει αρχεία τα οποία περιέχουν κείμενο και να εφαρμόσει τις μεθόδους οι οποίες αναπτύχθηκαν στις δύο προηγούμενες ασκήσεις. \n",
    "\n",
    "Το συγκεκριμέο μπορεί να πραγματοποιηθεί με την χρήση είτε for loop και της built-in βιβλιοθήκης os είτε με την χρήση της βιβλιοθήκης glob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "038363fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giann\\.Protege\\asd\n",
      "C:\\Users\\giann\\.Protege\\logs\n",
      "C:\\Users\\giann\\.Protege\\asd\\asd.txt\n",
      "C:\\Users\\giann\\.Protege\\logs\\protege.log\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for root, subdirectories, files in os.walk(r\"C:\\Users\\giann\\.Protege\"):\n",
    "    for subdirectory in subdirectories:\n",
    "        print(os.path.join(root, subdirectory))\n",
    "    for file in files:\n",
    "        print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5c0422",
   "metadata": {},
   "source": [
    " \n",
    "Αναδρομική εξερεύνηση φακέλων για την εύρεση αρχείων με την χρήση της βιβλιοθήκης **glob** \n",
    "\n",
    "Η χρήση της βιβλιοθήκης glob μας επιτρέπει να ψάξουμε αναδρομικά μια διαδρομή φακέλων και υποφακέλων για αρχεία είτε γενικώς είτε μιας συγκεκριμένης μορφής.  Τα παρακάτω παραδείγματα κώδικα μας δείχνουν \n",
    "\n",
    "Αναλυτική περιγραφή της βιβλιοθήκης glob μπορεί να βρεθεί στον παρακάτω σύνδεσμο: \n",
    "https://docs.python.org/3/library/glob.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9e92e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\giann']\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "print(glob.glob(\"C:\\\\Users\\\\giann\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dbb644c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\giann\\\\-1.14-windows.xml', 'C:\\\\Users\\\\giann\\\\3D Objects', 'C:\\\\Users\\\\giann\\\\anaconda3', 'C:\\\\Users\\\\giann\\\\ansel', 'C:\\\\Users\\\\giann\\\\AppData', 'C:\\\\Users\\\\giann\\\\Application Data', 'C:\\\\Users\\\\giann\\\\autokerasmodel.h5', 'C:\\\\Users\\\\giann\\\\clusters.json', 'C:\\\\Users\\\\giann\\\\Contacts', 'C:\\\\Users\\\\giann\\\\Cookies', 'C:\\\\Users\\\\giann\\\\Documents', 'C:\\\\Users\\\\giann\\\\Downloads', 'C:\\\\Users\\\\giann\\\\Favorites', 'C:\\\\Users\\\\giann\\\\final_pipeline_predictions.csv', 'C:\\\\Users\\\\giann\\\\getting-started', 'C:\\\\Users\\\\giann\\\\Image Classification Assignment.ipynb', 'C:\\\\Users\\\\giann\\\\Image Regression Assignment.ipynb', 'C:\\\\Users\\\\giann\\\\IntelGraphicsProfiles', 'C:\\\\Users\\\\giann\\\\java_error_in_pycharm64.hprof', 'C:\\\\Users\\\\giann\\\\Jedi', 'C:\\\\Users\\\\giann\\\\lab1.ipynb', 'C:\\\\Users\\\\giann\\\\Lab1_example.txt', 'C:\\\\Users\\\\giann\\\\Lab2.ipynb', 'C:\\\\Users\\\\giann\\\\left', 'C:\\\\Users\\\\giann\\\\Lightworks', 'C:\\\\Users\\\\giann\\\\Links', 'C:\\\\Users\\\\giann\\\\Local Settings', 'C:\\\\Users\\\\giann\\\\Music', 'C:\\\\Users\\\\giann\\\\NetHood', 'C:\\\\Users\\\\giann\\\\NTUSER.DAT', 'C:\\\\Users\\\\giann\\\\ntuser.dat.LOG1', 'C:\\\\Users\\\\giann\\\\ntuser.dat.LOG2', 'C:\\\\Users\\\\giann\\\\NTUSER.DAT{53b39e88-18c4-11ea-a811-000d3aa4692b}.TM.blf', 'C:\\\\Users\\\\giann\\\\NTUSER.DAT{53b39e88-18c4-11ea-a811-000d3aa4692b}.TMContainer00000000000000000001.regtrans-ms', 'C:\\\\Users\\\\giann\\\\NTUSER.DAT{53b39e88-18c4-11ea-a811-000d3aa4692b}.TMContainer00000000000000000002.regtrans-ms', 'C:\\\\Users\\\\giann\\\\NTUSER.DAT{e4ecbd7e-a9a4-11eb-9b60-a8a159608f4a}.TxR.0.regtrans-ms', 'C:\\\\Users\\\\giann\\\\NTUSER.DAT{e4ecbd7e-a9a4-11eb-9b60-a8a159608f4a}.TxR.1.regtrans-ms', 'C:\\\\Users\\\\giann\\\\NTUSER.DAT{e4ecbd7e-a9a4-11eb-9b60-a8a159608f4a}.TxR.2.regtrans-ms', 'C:\\\\Users\\\\giann\\\\NTUSER.DAT{e4ecbd7e-a9a4-11eb-9b60-a8a159608f4a}.TxR.blf', 'C:\\\\Users\\\\giann\\\\NTUSER.DAT{e4ecbd7f-a9a4-11eb-9b60-a8a159608f4a}.TM.blf', 'C:\\\\Users\\\\giann\\\\NTUSER.DAT{e4ecbd7f-a9a4-11eb-9b60-a8a159608f4a}.TMContainer00000000000000000001.regtrans-ms', 'C:\\\\Users\\\\giann\\\\NTUSER.DAT{e4ecbd7f-a9a4-11eb-9b60-a8a159608f4a}.TMContainer00000000000000000002.regtrans-ms', 'C:\\\\Users\\\\giann\\\\ntuser.ini', 'C:\\\\Users\\\\giann\\\\OneDrive', 'C:\\\\Users\\\\giann\\\\ontospy-viz-test', 'C:\\\\Users\\\\giann\\\\Postman', 'C:\\\\Users\\\\giann\\\\prepare_resources_graph.ipynb', 'C:\\\\Users\\\\giann\\\\PrintHood', 'C:\\\\Users\\\\giann\\\\PycharmProjects', 'C:\\\\Users\\\\giann\\\\Recent', 'C:\\\\Users\\\\giann\\\\right', 'C:\\\\Users\\\\giann\\\\Saved Games', 'C:\\\\Users\\\\giann\\\\Searches', 'C:\\\\Users\\\\giann\\\\SendTo', 'C:\\\\Users\\\\giann\\\\Start Menu', 'C:\\\\Users\\\\giann\\\\Templates', 'C:\\\\Users\\\\giann\\\\Untitled.ipynb', 'C:\\\\Users\\\\giann\\\\Videos', 'C:\\\\Users\\\\giann\\\\VirtualBox VMs', 'C:\\\\Users\\\\giann\\\\Xtest.txt', 'C:\\\\Users\\\\giann\\\\Xtrain.txt', 'C:\\\\Users\\\\giann\\\\Ytrain.htm', 'C:\\\\Users\\\\giann\\\\Ytrain.txt', 'C:\\\\Users\\\\giann\\\\Τα έγγραφά μου']\n"
     ]
    }
   ],
   "source": [
    "print(glob.glob(\"C:\\\\Users\\\\giann\\**\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3094e349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\giann\\\\anaconda3\\\\LICENSE_PYTHON.txt',\n",
       " 'C:\\\\Users\\\\giann\\\\Downloads\\\\describe_nodes.txt',\n",
       " 'C:\\\\Users\\\\giann\\\\getting-started\\\\requirements.txt']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(\"C:\\\\Users\\\\giann\\**\\*.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da133f2",
   "metadata": {},
   "source": [
    "## Bonus - Reading Txt from PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dfa92d",
   "metadata": {},
   "source": [
    "Ακόμη κείμενο μπορεί να εξαχθεί από αρχεία pdf με την χρήση της βιβλιοθήκης pymupdf. Παρατίθεται παράδειγμα χρήσης της βιβλιοθήκης για την εξαγωγή κειμένου από κάθε σελίδας αρχείου.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f30ac416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy\n",
      "Article\n",
      "Benchmarking Analysis of the Accuracy of Classiﬁcation\n",
      "Methods Related to Entropy\n",
      "Yolanda Orenes †, Alejandro Rabasa †\n",
      ", Jesus Javier Rodriguez-Sala †\n",
      "and Joaquin Sanchez-Soriano *,†,‡\n",
      "����������\n",
      "�������\n",
      "Citation: Orenes, Y.; Rabasa, A.;\n",
      "Rodriguez-Sala, J.J.; Sanchez-Soriano,\n",
      "J. Benchmarking Analysis of the\n",
      "Accuracy of Classiﬁcation Methods\n",
      "Related to Entropy. Entropy 2021, 23,\n",
      "850. https://doi.org/10.3390/\n",
      "e23070850\n",
      "Academic Editor: Kevin R. Moon\n",
      "Received: 28 March 2021\n",
      "Accepted: 24 June 2021\n",
      "Published: 1 July 2021\n",
      "Publisher’s Note: MDPI stays neutral\n",
      "with regard to jurisdictional claims in\n",
      "published maps and institutional afﬁl-\n",
      "iations.\n",
      "Copyright: © 2021 by the authors.\n",
      "Licensee MDPI, Basel, Switzerland.\n",
      "This article is an open access article\n",
      "distributed\n",
      "under\n",
      "the\n",
      "terms\n",
      "and\n",
      "conditions of the Creative Commons\n",
      "Attribution (CC BY) license (https://\n",
      "creativecommons.org/licenses/by/\n",
      "4.0/).\n",
      "I.U.I. Centro de Investigación Operativa (CIO), Universidad Miguel Hernandez de Elche, 03202 Elche, Spain;\n",
      "yolanda.orenes@alu.umh.es (Y.O.); a.rabasa@umh.es (A.R.); jesuja.rodriguez@umh.es (J.J.R.-S.)\n",
      "* Correspondence: joaquin@umh.es\n",
      "† These authors contributed equally to this work.\n",
      "‡ Current address: Campus de Elche, Ediﬁcio Torretamarit, Avenida de la Universidad s/n, 03202 Elche, Spain.\n",
      "Abstract: In the machine learning literature we can ﬁnd numerous methods to solve classiﬁcation\n",
      "problems. We propose two new performance measures to analyze such methods. These measures are\n",
      "deﬁned by using the concept of proportional reduction of classiﬁcation error with respect to three\n",
      "benchmark classiﬁers, the random and two intuitive classiﬁers which are based on how a non-expert\n",
      "person could realize classiﬁcation simply by applying a frequentist approach. We show that these\n",
      "three simple methods are closely related to different aspects of the entropy of the dataset. Therefore,\n",
      "these measures account somewhat for entropy in the dataset when evaluating the performance of\n",
      "classiﬁers. This allows us to measure the improvement in the classiﬁcation results compared to\n",
      "simple methods, and at the same time how entropy affects classiﬁcation capacity. To illustrate how\n",
      "these new performance measures can be used to analyze classiﬁers taking into account the entropy\n",
      "of the dataset, we carry out an intensive experiment in which we use the well-known J48 algorithm,\n",
      "and a UCI repository dataset on which we have previously selected a subset of the most relevant\n",
      "attributes. Then we carry out an extensive experiment in which we consider four heuristic classiﬁers,\n",
      "and 11 datasets.\n",
      "Keywords: entropy; classiﬁcation methods; intuitive classiﬁcation method; performance measures;\n",
      "benchmarking\n",
      "1. Introduction\n",
      "Classiﬁcation is one of the most relevant topics in machine learning [1–4]. In general,\n",
      "the purpose of supervised classiﬁcation is to predict the correct class , among a set of\n",
      "known classes, of a new observation given, based on the knowledge provided by a dataset,\n",
      "known as “training data”. In addition, the classiﬁcation problem is very important in\n",
      "decision-making in many different ﬁelds, so it is not difﬁcult to ﬁnd applications in ﬁelds\n",
      "such as medicine, biotechnology, marketing, security in communication networks, robotics,\n",
      "image and text recognition... Three issues in classiﬁcation problems are the attribute subset\n",
      "selection, the design and implementation of classiﬁers, and the performance evaluation of\n",
      "classiﬁers [1–4]. In this paper, we will focus mainly on the latter.\n",
      "On the other hand, entropy appears in statistics or information theory as a measure\n",
      "of diversity, uncertainty, randomness or even complexity. For this reason, we can ﬁnd the\n",
      "use of entropy in the feature selection problem and the design of classiﬁers. Shannon [5]\n",
      "introduced entropy in the context of communication and information theory. This concept\n",
      "has been used frequently in information-based learning models [2]. Two extensions of the\n",
      "Shannon entropy measure, which are also frequently used, are the Renyi’s entropy [6] and\n",
      "the Tsallis’ entropy [7]. In [8], a review on generalized entropies can be found.\n",
      "One of the most frequent difﬁculties found in the analysis of a dataset is that of high\n",
      "dimensionality, since when there are too many variables the analysis is more difﬁcult and\n",
      "computationally expensive, there may be correlated variables, redundant variables or even\n",
      "Entropy 2021, 23, 850. https://doi.org/10.3390/e23070850\n",
      "https://www.mdpi.com/journal/entropy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz \n",
    "\n",
    "pdf = fitz.open(r\"C:\\Users\\giann\\Downloads\\entropy-23-00850-v3.pdf\")\n",
    "for pagenum, page in enumerate(pdf.pages(), start=1):\n",
    "    page_txt = page.get_text()\n",
    "    print(page_txt)\n",
    "    break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
